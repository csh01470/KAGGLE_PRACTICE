{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "474d0294",
   "metadata": {},
   "source": [
    "# FEATURED : **RSNA 2024 Lumbar Spine Degenerative Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84460a64",
   "metadata": {},
   "source": [
    "## >> **BUILD DATASET**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea03c14e",
   "metadata": {},
   "source": [
    "- [LSDC Gen Yolo Data SS](https://www.kaggle.com/code/namgalielei/lsdc-gen-yolo-data-ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43b5ff9",
   "metadata": {},
   "source": [
    "## 00. **SET WORK ENVORINMENT**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe30092",
   "metadata": {},
   "source": [
    "#### 00.1. **DEFINE PRE-VARIABLE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7922bee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_num = 2024\n",
    "dataset_paths = f'../data/raw'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e142c44f",
   "metadata": {},
   "source": [
    "#### 00.2. **IMPORT PACKAGES AND SET OPTIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f313a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1) Import packages\n",
    "import os\n",
    "import warnings\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import iterstrat.ml_stratifiers\n",
    "import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "#(2) Set system options\n",
    "warnings.filterwarnings(action='ignore')\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "pd.options.display.max_rows = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3abfe3f",
   "metadata": {},
   "source": [
    "#### 00.3. **CREATE FUNCTIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c7a3631",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1)\n",
    "def get_level(text:str) -> str :\n",
    "    for lev in ['l1_l2', 'l2_l3', 'l3_l4', 'l4_l5', 'l5_s1']:\n",
    "        if lev in text :\n",
    "            split = lev.split('_')\n",
    "            split[0] = split[0].capitalize()\n",
    "            split[1] = split[1].capitalize()\n",
    "            return '/'.join(split)\n",
    "    raise ValueError(f'Level not found {lev}')\n",
    "    \n",
    "#(2) \n",
    "def get_condition(text:str) -> list :\n",
    "    split = text.split('_')\n",
    "    for i in range(len(split)) :\n",
    "        split[i] = split[i].capitalize()\n",
    "    split = split[:-2]\n",
    "    return ' '.join(split)\n",
    "\n",
    "#(3)\n",
    "def query_train_xy_row(tar_df, std_df, study_id, series_id=None, instance_num=None):\n",
    "    if series_id is not None and instance_num is not None:\n",
    "        return tar_df[(tar_df.study_id==study_id) & (tar_df.series_id==series_id) &\n",
    "            (tar_df.instance_number==instance_num)]\n",
    "    elif series_id is None and instance_num is None:\n",
    "        return tar_df[(tar_df.study_id==study_id)]\n",
    "    else:\n",
    "        return tar_df[(std_df.study_id==study_id) & (tar_df.series_id==series_id)]\n",
    "\n",
    "#(4) \n",
    "def read_dcm(src_path):\n",
    "    dicom_data = pydicom.dcmread(src_path)\n",
    "    image = dicom_data.pixel_array\n",
    "    image = (image - image.min()) / (image.max() - image.min() +1e-6) * 255\n",
    "    image = np.stack([image]*3, axis=-1).astype('uint8')\n",
    "    return image\n",
    "\n",
    "#(5)\n",
    "def get_accronym(text):\n",
    "    split = text.split(' ')\n",
    "    return ''.join([x[0] for x in split])\n",
    "\n",
    "#(6)\n",
    "def gen_yolo_format(OUT_DIR, IMG_DIR, ann_df, phase='train', ):\n",
    "    for name, group in tqdm(ann_df.groupby(['study_id', 'series_id', 'instance_number'])):\n",
    "        study_id, series_id, instance_num = name[0], name[1], name[2]\n",
    "        path = f'{IMG_DIR}/{study_id}/{series_id}/{instance_num}.dcm'\n",
    "        img = read_dcm(path)\n",
    "        H, W = img.shape[:2]\n",
    "\n",
    "        img_dir = os.path.join(OUT_DIR, 'images', phase)\n",
    "        os.makedirs(img_dir, exist_ok=True)\n",
    "        img_path = os.path.join(img_dir, f'{study_id}_{series_id}_{instance_num}.jpg')\n",
    "        cv2.imwrite(img_path, img)\n",
    "\n",
    "        ann_dir = os.path.join(OUT_DIR, 'labels', phase)\n",
    "        os.makedirs(ann_dir, exist_ok=True)\n",
    "        ann_path = os.path.join(ann_dir, f'{study_id}_{series_id}_{instance_num}.txt')\n",
    "        \n",
    "        contain_nulls = False\n",
    "        \n",
    "        with open(ann_path, 'w') as f:\n",
    "            for i, row in group.iterrows():\n",
    "                try : \n",
    "                    cond = row['condition']\n",
    "                    level = row['level']\n",
    "                    severity = row['label']\n",
    "                    if pd.isnull(severity):\n",
    "                        contain_nulls = True\n",
    "                        break\n",
    "                    # class_label = f\"{cond.lower().replace(' ', '_')}_{level.lower().replace('/', '_')}_{severity.lower()}\"\n",
    "                    class_label = (\n",
    "                        f\"{cond.lower().replace(' ', '_')}_\"\n",
    "                        f\"{level.lower().replace('/', '_')}_\"\n",
    "                        f\"{severity.lower().replace('/', '_')}\"\n",
    "                    )\n",
    "                    class_id = lb2id[class_label]\n",
    "                    x_center = row['x'] / W\n",
    "                    y_center = row['y'] / H\n",
    "                    width = W / OD_INPUT_SIZE * STD_BOX_SIZE / W\n",
    "                    height = H /  OD_INPUT_SIZE * STD_BOX_SIZE / H\n",
    "                    f.write(f'{class_id} {x_center} {y_center} {width} {height}\\n')\n",
    "                except : \n",
    "                    pass\n",
    "        \n",
    "        if not contain_nulls:\n",
    "            cv2.imwrite(img_path, img)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f45cce",
   "metadata": {},
   "source": [
    "#### 00.4. **CREATE CLASSES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f5ec89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59968db6",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f9b111",
   "metadata": {},
   "source": [
    "## 01. **READ AND CONCATENATE DATASETS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9d03c9",
   "metadata": {},
   "source": [
    "##### 01.1. **READ DATASETS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a83cbd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1) Read Datasets\n",
    "train_desc_raw = pd.read_csv(filepath_or_buffer=f'{dataset_paths}/train_series_descriptions.csv') # id 별 description ? (MRI 이미지 측정 기법?같은 설명인듯) \n",
    "train_coord_raw = pd.read_csv(filepath_or_buffer=f'{dataset_paths}/train_label_coordinates.csv')  # 이미지 데이터의 좌표값(x, y) \n",
    "train_label_raw = pd.read_csv(filepath_or_buffer=f'{dataset_paths}/train.csv')                    # 멀티 라벨(정답값배열) \n",
    "test_desc_raw = pd.read_csv(filepath_or_buffer=f'{dataset_paths}/test_series_descriptions.csv')\n",
    "submission_raw = pd.read_csv(filepath_or_buffer=f'{dataset_paths}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b5d203",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed1c9a9",
   "metadata": {},
   "source": [
    "##### 01.2. **SPLIT DATASETS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5205626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1)\n",
    "train_label = train_label_raw.fillna(value='Unknown')\n",
    "\n",
    "#(2)\n",
    "mskf = iterstrat.ml_stratifiers.MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "#(3)\n",
    "fold = 0\n",
    "for train_index, test_index in mskf.split(X=train_label, y=train_label.iloc[:,1:]):\n",
    "    train_label.loc[test_index, 'fold_num'] = fold\n",
    "    fold += 1\n",
    "\n",
    "#(4)\n",
    "train_label['fold_num'] = train_label['fold_num'].astype(dtype='int')\n",
    "\n",
    "#(5)\n",
    "fold_idx = train_label.loc[:, ['study_id', 'fold_num']]\n",
    "\n",
    "#(6)\n",
    "fold_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a7838d",
   "metadata": {},
   "source": [
    "##### 01.3. **_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcf2e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1) \n",
    "train_label_lf = {\n",
    "    'study_id'  : [], \n",
    "    'condition' : [], \n",
    "    'level'     : [], \n",
    "    'label'     : []\n",
    "}\n",
    "for i, row in train_label_raw.iterrows() :\n",
    "    study_id = row['study_id']\n",
    "    for k, label in row.iloc[1:].to_dict().items() :\n",
    "        level = get_level(k)\n",
    "        condition = get_condition(k)\n",
    "        train_label_lf['study_id'].append(study_id)\n",
    "        train_label_lf['condition'].append(condition)\n",
    "        train_label_lf['level'].append(level)\n",
    "        train_label_lf['label'].append(label)\n",
    "\n",
    "#(2)\n",
    "train_label_lf = pd.DataFrame(data=train_label_lf)\n",
    "\n",
    "#(3)\n",
    "train_label_lf = pd.merge(\n",
    "    left=train_label_lf, \n",
    "    right=fold_idx, \n",
    "    on='study_id'\n",
    ")\n",
    "train_xy = pd.merge(\n",
    "    left=train_coord_raw,\n",
    "    right=train_desc_raw, \n",
    "    how='inner', \n",
    "    on=['study_id', 'series_id']\n",
    ")\n",
    "train_label_lf = pd.merge(\n",
    "    left=train_label_lf,\n",
    "    right=train_xy, \n",
    "    how='inner', \n",
    "    on=['study_id', 'condition', 'level']\n",
    ")\n",
    "\n",
    "#(4)\n",
    "train_label_lf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428b94f0",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10096754",
   "metadata": {},
   "source": [
    "## 02."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55aac4eb",
   "metadata": {},
   "source": [
    "##### 02.1. **CHECK SAMPLE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a334cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1)\n",
    "example = train_label_lf.sample(n=1).iloc[0, :]\n",
    "study_id = example.study_id\n",
    "series_id = example.series_id\n",
    "instance_num = example.instance_number\n",
    "src_path = f'{dataset_paths}/train_images/{study_id}/{series_id}/{instance_num}.dcm'\n",
    "\n",
    "#(2)\n",
    "img = read_dcm(src_path=src_path)\n",
    "\n",
    "#(3)\n",
    "tmp_df = query_train_xy_row(\n",
    "    tar_df=train_label_lf, \n",
    "    std_df=train_xy, \n",
    "    study_id=study_id, \n",
    "    series_id=series_id, \n",
    "    instance_num=instance_num\n",
    ")\n",
    "\n",
    "#(4)\n",
    "tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff671082",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(5)\n",
    "WIDTH = 10\n",
    "OD_INPUT_SIZE = 384\n",
    "STD_BOX_SIZE = 20\n",
    "for i, row in tmp_df.iterrows():\n",
    "    lbl = f\"{get_accronym(row['condition'])}_{row['level']}\"\n",
    "    x, y = row['x'], row['y']\n",
    "    x1 = int(x - WIDTH)\n",
    "    x2 = int(x + WIDTH)\n",
    "    y1 = int(y - WIDTH)\n",
    "    y2 = int(y + WIDTH)\n",
    "    color = None\n",
    "    if row['label'] == 'Normal/Mild':\n",
    "        color =  (0, 255, 0) # GREEN\n",
    "    elif row['label'] == 'Moderate':\n",
    "        color = (255,255,0) # YELLOW\n",
    "    elif row['label'] == 'Severe':\n",
    "        color = (255,0,0) # RED\n",
    "        \n",
    "    fontFace = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    fontScale = 0.5\n",
    "    thickness = 1\n",
    "    cv2.rectangle(img, (x1,y1), (x2,y2), color, 2)\n",
    "    cv2.putText(img, lbl, (x1,y1), fontFace, fontScale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "#(6)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d915034",
   "metadata": {},
   "source": [
    "##### 02.2. **_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed9dece",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1)\n",
    "conditions = ['Left Subarticular Stenosis', 'Right Subarticular Stenosis']\n",
    "# conditions = train_label_lf.loc[:, 'condition'].unique()\n",
    "severities = ['Normal/Mild', 'Moderate', 'Severe']\n",
    "levels = ['l1_l2', 'l2_l3', 'l3_l4', 'l4_l5', 'l5_s1']\n",
    "\n",
    "#(2)\n",
    "train_label_lf_flt = train_label_lf[train_label_lf.condition.map(lambda x: x in conditions)]\n",
    "\n",
    "#(3)\n",
    "train_label_lf_flt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dc4ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(4)\n",
    "lb2id = {}\n",
    "id2lb = {}\n",
    "i = 0\n",
    "for cond in conditions :\n",
    "    for level in levels :\n",
    "        for severity in severities :\n",
    "            cls_ = f\"{cond.lower().replace(' ', '_')}_{level}_{severity.lower()}\"\n",
    "            lb2id[cls_] = i\n",
    "            id2lb[i] = cls_\n",
    "            i+=1\n",
    "\n",
    "#(5)\n",
    "id2lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66b8b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(6)\n",
    "folds = [0, 1, 2, 3, 4]\n",
    "img_path = f'{dataset_paths}/train_images'\n",
    "\n",
    "#(4) \n",
    "for fold in folds :\n",
    "    print('>> Gen data fold', fold)\n",
    "    output_path = f'../data/yolo/fold{fold}'\n",
    "    os.makedirs(name=output_path, exist_ok=True)\n",
    "    \n",
    "    train_df = train_label_lf_flt[train_label_lf_flt.fold_num != fold]\n",
    "    val_df = train_label_lf_flt[train_label_lf_flt.fold_num == fold]\n",
    "    \n",
    "    gen_yolo_format(IMG_DIR=img_path, OUT_DIR=output_path, ann_df=train_df, phase='train')\n",
    "    gen_yolo_format(IMG_DIR=img_path, OUT_DIR=output_path, ann_df=val_df, phase='val')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9045607,
     "sourceId": 76727,
     "sourceType": "competition"
    },
    {
     "datasetId": 478,
     "sourceId": 974,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "PYTCH_YOLO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 159.349778,
   "end_time": "2024-08-04T03:40:44.363345",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-04T03:38:05.013567",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
