{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "474d0294",
   "metadata": {},
   "source": [
    "# FEATURED : **RSNA 2024 Lumbar Spine Degenerative Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38407105",
   "metadata": {},
   "source": [
    "## >> **EDA**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43b5ff9",
   "metadata": {},
   "source": [
    "## 00. **SET WORK ENVORINMENT**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546dfa4d",
   "metadata": {},
   "source": [
    "#### 00.1. **DEFINE PRE-VARIABELS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eab113a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_num = 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e142c44f",
   "metadata": {},
   "source": [
    "#### 00.2. **IMPORT PACKAGES AND SET OPTIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f313a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1) Import packages\n",
    "import os\n",
    "import warnings\n",
    "import glob\n",
    "# import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from matplotlib import rc\n",
    "\n",
    "#(2) Set system options\n",
    "warnings.filterwarnings(action='ignore')\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "pd.options.display.max_rows = 150\n",
    "rc(group='animation', html='jshtml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3abfe3f",
   "metadata": {},
   "source": [
    "#### 00.3. **CREATE FUNCTIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c7a3631",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1) Create `relocate_col()` function\n",
    "def relocate_col(df:pd.DataFrame, tar_col:str, std_col:str, how:str='after') -> pd.DataFrame : \n",
    "    '''\n",
    "    Reorder columns in a DataFrame by moving a target column relative to a standard column.\n",
    "\n",
    "    Parameters :\n",
    "    - df (pd.DataFrame): The DataFrame from which the column will be relocated.\n",
    "    - tar_col (str): The name of the column to be relocated.\n",
    "    - std_col (str): The column relative to which `tar_col` will be relocated.\n",
    "    - how (str, optional): Specifies the placement of `tar_col` relative to `std_col`.\n",
    "      It can be 'after' (default) or 'before'.\n",
    "\n",
    "    Returns :\n",
    "    - pd.DataFrame: A new DataFrame with the column `tar_col` relocated as specified.\n",
    "    '''\n",
    "    col_ary = np.array(object=df.columns)\n",
    "    tar_col_idx = np.where(col_ary==tar_col)[0][0]\n",
    "    std_col_idx = np.where(col_ary==std_col)[0][0]\n",
    "    col_ary = np.delete(arr=col_ary, obj=tar_col_idx)\n",
    "    if how == 'after' : \n",
    "        if std_col_idx == len(col_ary) : \n",
    "            col_ary = np.insert(arr=col_ary, obj=std_col_idx, values=tar_col)\n",
    "        else :\n",
    "            col_ary = np.insert(arr=col_ary, obj=std_col_idx+1, values=tar_col)\n",
    "    elif how == 'before' : \n",
    "        if std_col_idx == 0 : \n",
    "            col_ary = np.insert(arr=col_ary, obj=std_col_idx, values=tar_col) \n",
    "        else : \n",
    "            col_ary = np.insert(arr=col_ary, obj=std_col_idx-1, values=tar_col)\n",
    "    else : \n",
    "        pass\n",
    "    df = df.loc[:, col_ary]\n",
    "    return df \n",
    "\n",
    "#(2) Create `diagnose_df()` function\n",
    "def diagnose_df(df:pd.DataFrame) -> pd.DataFrame : \n",
    "    '''\n",
    "    Generates a diagnostic summary for a pandas DataFrame, reporting details like data types, \n",
    "    count of missing values, and uniqueness for each column.\n",
    "\n",
    "    Parameters :\n",
    "    - df (pd.DataFrame): The DataFrame to be diagnosed.\n",
    "\n",
    "    Returns :\n",
    "    - pd.DataFrame: A summary table with diagnostics for each column in the input DataFrame, \n",
    "      including the column name, data type, total rows, count and rate of missing values, \n",
    "      and count and rate of unique values.\n",
    "    '''\n",
    "    output = pd.DataFrame(data=df.dtypes).reset_index()\n",
    "    output.columns = ['COLUMN_NM', 'DATA_TYPE']\n",
    "    output.loc[:, 'ROW_CNT'] = len(df)\n",
    "    output.loc[:, 'NA_CNT'] = df.isna().sum().values\n",
    "    output.loc[:, 'NA_RATE'] = output.loc[:, 'NA_CNT'] / output.loc[:, 'ROW_CNT']\n",
    "    output.loc[:, 'UNIQUE_CNT'] = df.nunique().values\n",
    "    output.loc[:, 'UNIQUE_RATE'] = output.loc[:, 'UNIQUE_CNT'] / output.loc[:, 'ROW_CNT']\n",
    "    format_columns = ['ROW_CNT', 'NA_CNT', 'UNIQUE_CNT']\n",
    "    for col in format_columns:\n",
    "        output[col] = output[col].apply(func=lambda x: f'{x:,.0f}')\n",
    "    return output\n",
    "\n",
    "#(3) Create `check_grby_cnt()` function\n",
    "def check_grby_cnt(df: pd.DataFrame, grby_cols: list, cnt_col: str, cnt_col_nm: str) -> pd.DataFrame :\n",
    "    output = df.groupby(\n",
    "        by=grby_cols, \n",
    "        as_index=False\n",
    "    ).agg(\n",
    "        {cnt_col: 'nunique'}\n",
    "    ).rename(\n",
    "        columns={cnt_col: cnt_col_nm}\n",
    "    )\n",
    "    return output\n",
    "\n",
    "#(4) Create `get_grby_outlier_pk()` function\n",
    "def get_grby_outlier_pk(df:pd.DataFrame, grby_cols:list, cnt_col:str, tar_col:str, condition:str) -> np.array : \n",
    "    temp = check_grby_cnt(df=df, grby_cols=grby_cols, cnt_col=cnt_col, cnt_col_nm='_') \n",
    "    CON = eval(f'(temp.loc[:, \"_\"] {condition})')\n",
    "    output = temp.loc[CON, tar_col].unique()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0c2ca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(5)\n",
    "def check_img(dir_path:str, coord_df:pd.DataFrame, desc_df:pd.DataFrame, study_id:str, series_id:str) -> plt.figure :\n",
    "    '''\n",
    "    '''\n",
    "    img_path = f'{dir_path}/train_images/{study_id}/{series_id}'\n",
    "    dicom_files = [f for f in os.listdir(img_path) if f.endswith('.dcm')]\n",
    "    CON = (coord_df.loc[:, 'series_id'] == int(series_id))\n",
    "    study_label_coordinates = coord_df.loc[CON, :]\n",
    "    CON = (desc_df.loc[:, 'series_id'] == series_id)\n",
    "    series_description = desc_df.loc[CON, 'series_description'].unique()\n",
    "\n",
    "    filtered_dicom_files = []\n",
    "    filtered_label_coordinates = []\n",
    "\n",
    "    for dicom_file in dicom_files :\n",
    "        instance_number = int(dicom_file.split('.')[0])\n",
    "        CON = (study_label_coordinates.loc[:, 'instance_number'] == instance_number)\n",
    "        corresponding_coordinates = study_label_coordinates.loc[CON, :]\n",
    "        if not corresponding_coordinates.empty :\n",
    "            filtered_dicom_files.append(dicom_file)\n",
    "            filtered_label_coordinates.append(corresponding_coordinates)\n",
    "\n",
    "    num_images = len(filtered_dicom_files)\n",
    "    num_columns = 5\n",
    "    num_rows = (num_images + num_columns - 1) // num_columns\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=num_rows, ncols=num_columns, figsize=(4 * num_columns, 4 * num_rows))\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    for i, (dicom_file, label_coordinates) in enumerate(zip(filtered_dicom_files, filtered_label_coordinates)) :\n",
    "        dicom_data = pydicom.dcmread(fp=os.path.join(img_path, dicom_file))\n",
    "        image = dicom_data.pixel_array\n",
    "        axs[i].imshow(X=image, cmap='gray')\n",
    "        axs[i].set_title(label=f'{study_id}/{series_id}/{dicom_file}')\n",
    "\n",
    "        conditions = ','.join(label_coordinates.loc[:, 'condition'].unique())\n",
    "        level = ','.join(map(str, label_coordinates.loc[:, 'level'].unique()))\n",
    "\n",
    "        axs[i].set_xlabel(xlabel=f'Series Descriptions: {series_description} \\n Conditions: {conditions} \\n Level: {level}', fontsize=8)\n",
    "        # axs[i].axis(option='on')  # Ensure axis is on to display labels\n",
    "\n",
    "        # Ensure the plotting of red circles\n",
    "        for _, row in label_coordinates.iterrows():\n",
    "            axs[i].plot(row['x'], row['y'], 'o', markerfacecolor='none', markeredgecolor='red', markersize=10, markeredgewidth=2)\n",
    "\n",
    "    for ax in axs[i+1:]:\n",
    "        ax.set_visible(False)\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.5, wspace=0.5)  # Adjust spacing to make sure labels and titles do not overlap\n",
    "    plt.show()\n",
    "\n",
    "#(6)\n",
    "def check_vid(dir_path:str, coord_df, desc_df, study_id:int, series_id:int) -> animation.FuncAnimation :\n",
    "    # Load DICOM files sorted by the number in filenames\n",
    "    img_path = f'{dir_path}/train_images/{study_id}/{series_id}'\n",
    "    t_paths = sorted(\n",
    "        glob.glob(os.path.join(img_path, \"*\")), \n",
    "        key=lambda x: int(os.path.splitext(os.path.basename(x))[0].split(\"-\")[-1])\n",
    "    )\n",
    "    images = []\n",
    "    coordinates = []  # Store coordinates for each image\n",
    "    series_description = desc_df[desc_df['series_id'] == int(series_id)]['series_description'].unique()\n",
    "    conditions = coord_df[coord_df['series_id'] == int(series_id)]['condition'].unique()\n",
    "    \n",
    "    # Read DICOM files into an image list and extract coordinates\n",
    "    for filename in t_paths:\n",
    "        instance_number = int(os.path.splitext(os.path.basename(filename))[0].split(\"-\")[-1])\n",
    "        ds = pydicom.dcmread(filename)\n",
    "        data = ds.pixel_array\n",
    "        if data.max() == 0:  # Skip images with no maximum pixel value\n",
    "            continue\n",
    "        \n",
    "        images.append(data)\n",
    "        \n",
    "        # Extract coordinates for this instance number\n",
    "        instance_coords = coord_df[(coord_df['series_id'] == int(series_id)) & (coord_df['instance_number'] == instance_number)]\n",
    "        image_coords = [(row['x'], row['y']) for index, row in instance_coords.iterrows()]\n",
    "        coordinates.append(image_coords)\n",
    "\n",
    "    # Create an animation of the images with markers\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    ax.axis('off')\n",
    "    im = ax.imshow(images[0], cmap=\"gray\")\n",
    "    title_text = ax.text(x=0.5, y=1.05, s='', transform=ax.transAxes, ha=\"center\", fontsize=16)\n",
    "    label_text = ax.text(0.5, -0.1, \"\", transform=ax.transAxes, ha=\"center\", fontsize=12)\n",
    "\n",
    "    # Initialize markers (empty at start)\n",
    "    markers, = ax.plot([], [], 'o', markerfacecolor='none', markeredgecolor='red', markersize=10, markeredgewidth=2)\n",
    "\n",
    "    def animate_func(i):\n",
    "        im.set_array(images[i])\n",
    "        title_text.set_text(f'{study_id}/{series_id}')\n",
    "        label_text.set_text(f'Series Descriptions: {series_description} \\nConditions: {conditions}')\n",
    "        if i < len(coordinates) and coordinates[i]:  # Update markers if coordinates are available\n",
    "            x_coords, y_coords = zip(*coordinates[i])\n",
    "            markers.set_data(x_coords, y_coords)\n",
    "        else:\n",
    "            markers.set_data([], [])  # No markers for this frame\n",
    "        return [im, markers, title_text, label_text]\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, animate_func, frames=len(images), interval=500)\n",
    "    plt.close(fig)\n",
    "    return anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6f077af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(7)\n",
    "def reshape_row(row) -> pd.DataFrame :\n",
    "    data = {'study_id': [], 'condition': [], 'level': [], 'severity': []}\n",
    "    \n",
    "    for column, value in row.items():\n",
    "        if column not in ['study_id', 'series_id', 'instance_number', 'x', 'y', 'series_description']:\n",
    "            parts = column.split('_')\n",
    "            condition = ' '.join([word.capitalize() for word in parts[:-2]])\n",
    "            level = parts[-2].capitalize() + '/' + parts[-1].capitalize()\n",
    "            data['study_id'].append(row['study_id'])\n",
    "            data['condition'].append(condition)\n",
    "            data['level'].append(level)\n",
    "            data['severity'].append(value)\n",
    "    \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f45cce",
   "metadata": {},
   "source": [
    "#### 00.4. **CREATE CLASSES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f5ec89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59968db6",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f9b111",
   "metadata": {},
   "source": [
    "## 01. **READ AND CONCATENATE DATASETS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9d03c9",
   "metadata": {},
   "source": [
    "##### 01.1. **READ DATASETS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a83cbd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1) Define file-path\n",
    "file_path = f'{os.getcwd()}/../data/raw'\n",
    "\n",
    "#(2) Read Datasets\n",
    "train_desc_raw = pd.read_csv(filepath_or_buffer=f'{file_path}/train_series_descriptions.csv') # id 별 description ? (MRI 이미지 측정 기법?같은 설명인듯) \n",
    "train_coord_raw = pd.read_csv(filepath_or_buffer=f'{file_path}/train_label_coordinates.csv')  # 이미지 데이터의 좌표값(x, y) \n",
    "train_label_raw = pd.read_csv(filepath_or_buffer=f'{file_path}/train.csv')                    # 멀티 라벨(정답값배열) \n",
    "test_desc_raw = pd.read_csv(filepath_or_buffer=f'{file_path}/test_series_descriptions.csv')\n",
    "submission_raw = pd.read_csv(filepath_or_buffer=f'{file_path}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41faa6ef",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f39355",
   "metadata": {},
   "source": [
    "## 02. **EDA**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6c8112",
   "metadata": {},
   "source": [
    "#### 02.1. **`train_series_descriptions` 파악**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26626ab3",
   "metadata": {},
   "source": [
    "- 총 $ \\, 1975 $ 개의 study_id 중 $ \\, 3 $ 개의 유일한 촬영기법(description)을 갖지 않는 study_id 파악 : $ 343 $ 개\n",
    "\n",
    "$ \\hspace{0.5cm} $ ($ 340 $ 개의 study_id는 $ \\, 3 $ 개 이상의 중복된 촬영기법, $ \\, 3 $ 개의 study_id는 $ \\, 2 $ 개 이하의 촬영기법)\n",
    "\n",
    "- 총 $ \\, 6294 $ 개의 study_id 중 중복된 촬영 기법을 갖는 series_id 파악 : $ \\, 714 $ 개\n",
    "\n",
    "$ \\hspace{0.5cm} $ ($ 700 $ 개의 study_id는 axial T2 촬영기법, $ \\, 14 $ 개의 study_id는 Sagittal T1 촬영기법)\n",
    "\n",
    "$ \\hspace{0.5cm} \\Rightarrow{} $ 02.2. `coord` 데이터셋 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0300cb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1)\n",
    "diagnose_df(df=train_desc_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d208bd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(2)\n",
    "pd.DataFrame(\n",
    "    data=check_grby_cnt(df=train_desc_raw, grby_cols=['study_id'], cnt_col='series_id', cnt_col_nm='series_cnt').value_counts(subset='series_cnt')\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242df7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_id_nt3_desc = get_grby_outlier_pk(\n",
    "    df=train_desc_raw.sort_values(by='series_description'), \n",
    "    grby_cols=['study_id'], \n",
    "    cnt_col='series_id', \n",
    "    tar_col='study_id', \n",
    "    condition='!= 3'\n",
    ")\n",
    "study_id_nt3_desc = np.unique(study_id_nt3_desc)\n",
    "print(f'>> study id that has not 3 descriptions : {len(study_id_nt3_desc)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfa4377",
   "metadata": {},
   "outputs": [],
   "source": [
    "CON = (train_desc_raw.loc[:, 'study_id'].isin(values=study_id_nt3_desc))\n",
    "temp = train_desc_raw.loc[CON, :]\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a608def1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(3)\n",
    "CON = temp.duplicated(subset=['study_id', 'series_description'], keep=False)\n",
    "series_id_nt3_desc = temp.loc[CON, 'series_id'].values\n",
    "CON = train_desc_raw.loc[:, 'series_id'].isin(values=series_id_nt3_desc)\n",
    "study_id_ov3_desc = train_desc_raw.loc[CON, 'study_id'].unique()\n",
    "study_id_un3_desc = study_id_nt3_desc[~np.isin(element=study_id_nt3_desc, test_elements=study_id_ov3_desc)]\n",
    "pd.DataFrame(data=train_desc_raw.loc[CON, :].value_counts(subset='series_description')).reset_index().rename(columns={'count':'series_cnt'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2ca77e",
   "metadata": {},
   "source": [
    "#### 02.2. **`train_label_coordinates` 파악**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc3440e",
   "metadata": {},
   "source": [
    "##### 02.2.1. **정형 데이터 파악**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2148fb7b",
   "metadata": {},
   "source": [
    "- 중복된 촬영기법을 갖는 $ \\, 343 $ 개의 study_id 의 이유 \n",
    "\n",
    "$ \\hspace{0.5cm} \\rightarrow{} $ axial T2 에서 증상(condition) LSS, RSS 를 파악하기 위함 (단, 한 series_id 로도 잡을 때도 있음)\n",
    "\n",
    "$ \\hspace{0.975cm} $ 추가로 증상 판단을 위한 모든 디스크 위치(level) 이 한 series_id 에 안잡힐 때도 있어 여러 번 촬영\n",
    "\n",
    "$ \\hspace{0.975cm} $ ($ 631 $ 개의 series_id 는 **일부 디스크 위치가 존재하지 않음**)\n",
    "\n",
    "$ \\hspace{0.6cm} \\Rightarrow{} $ series_id 는 **중요하지 않음**\n",
    "\n",
    "- `train_series_description` 데이터셋 보다 study_id, series_id **적음** $ \\rightarrow{} $ 추후 결합할 때 inner join 해야할 듯\n",
    "\n",
    "- 총 $ \\, 1974 $ 개의 study_id, condition 결합키 중 $ \\, 5 $ 개의 디스크 위치를 갖지 않는 키 파악 : $ \\, 183 $ 개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9248690c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1)\n",
    "diagnose_df(df=train_coord_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c538fc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(2)\n",
    "CON = (\n",
    "    (train_coord_raw.loc[:, 'study_id'].isin(values=study_id_nt3_desc)) &\n",
    "    (train_coord_raw.loc[:, 'series_id'].isin(values=series_id_nt3_desc)) \n",
    ")\n",
    "train_coord_raw.loc[CON, :].sort_values(by=['study_id', 'condition', 'level']).head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d71f912",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(3)\n",
    "# pd.DataFrame(\n",
    "#     data=check_grby_cnt(df=train_coord_raw, grby_cols=['study_id', 'series_id'], cnt_col='level', cnt_col_nm='level_cnt').value_counts(subset='level_cnt')\n",
    "# ).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7e00a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# series_id_nt5_level = get_grby_outlier_pk(\n",
    "#     df=train_coord_raw, \n",
    "#     grby_cols=['study_id', 'series_id'], \n",
    "#     cnt_col='level', \n",
    "#     tar_col='series_id', \n",
    "#     condition='!= 5'\n",
    "# )\n",
    "# print(f'>> series id that has not 5 level : {len(series_id_nt5_level)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0eab1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(data=temp.value_counts(subset='condition')).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fba5b29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp.loc[CON, :].head(n=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842d6a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(4)\n",
    "pd.DataFrame(\n",
    "    data=check_grby_cnt(df=train_coord_raw, grby_cols=['study_id', 'condition'], cnt_col='level', cnt_col_nm='level_cnt').value_counts(subset='level_cnt')\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ace6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_id_nt5_level = get_grby_outlier_pk(\n",
    "    df=train_coord_raw, \n",
    "    grby_cols=['study_id', 'condition'], \n",
    "    cnt_col='level', \n",
    "    tar_col='study_id', \n",
    "    condition='!= 5'\n",
    ")\n",
    "\n",
    "print(f'>> study id (and condition) that has not 5 descriptions : {len(study_id_nt5_level)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1b9a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CON = (train_coord_raw.loc[:, 'study_id'].isin(values=study_id_nt5_level))\n",
    "train_coord_raw.loc[CON, :].head(n=21).sort_values(by=['study_id', 'condition', 'level'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2a6d73",
   "metadata": {},
   "source": [
    "##### 02.2.2. **이미지 파악**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f950dfc5",
   "metadata": {},
   "source": [
    "- 여러 이미지(instance) 중 일부만 `train_series_description` 데이터셋의 좌표가 찍혀있는 이유 $ \\rightarrow{} $ 디스크 위치의 정확한 식별이 안되서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43a419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(4)\n",
    "# tar_study_list = np.array(object=os.listdir(path=f'{file_path}/train_images/'))\n",
    "tar_study_list = train_coord_raw.loc[:, 'study_id'].unique()\n",
    "tar_study_idx = 1900\n",
    "tar_study = int(tar_study_list[tar_study_idx])\n",
    "tar_series_list = [f for f in os.listdir(path=f'{file_path}/train_images/{tar_study}') if not f.endswith('.DS_Store')]\n",
    "tar_series_idx = 2\n",
    "tar_series = int(tar_series_list[tar_series_idx])\n",
    "CON = train_desc_raw.loc[:, 'series_id'] == tar_series\n",
    "tar_desc = train_desc_raw.loc[CON, 'series_description'].values\n",
    "# img_path = f'{file_path}/train_images/{tar_study}/{tar_series}'\n",
    "print(f'>> Target study id : \"{tar_study}\"')\n",
    "print(f'   (index : \"{tar_study_idx}\", max index : \"{len(tar_study_list)}\")')\n",
    "print(f'>> Target series id : \"{tar_series}\"')\n",
    "print(f'   (index : \"{tar_series_idx}\", max index : \"{len(tar_series_list)}\")')\n",
    "print(f'>> Target Description : {tar_desc}')\n",
    "# print(f'>> Image Count : {len(os.listdir(path=file_path))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf20458d",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_img(dir_path=file_path, coord_df=train_coord_raw, desc_df=train_desc_raw, study_id=tar_study, series_id=tar_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa06167",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(4)\n",
    "check_vid(dir_path=file_path, coord_df=train_coord_raw, desc_df=train_desc_raw, study_id=tar_study, series_id=tar_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1d129c",
   "metadata": {},
   "source": [
    "##### PLUS. **$ \\, 343 $ 개의 중복된 촬영 기법(description)을 갖는 `study_id` 파악**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed32f177",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1)\n",
    "tar_study_idx = 175\n",
    "\n",
    "#(2)\n",
    "CON = (\n",
    "    (train_desc_raw.loc[:, 'series_id'].isin(values=series_id_nt3_desc)) &\n",
    "    (train_desc_raw.loc[:, 'study_id'] == study_id_nt3_desc[tar_study_idx])\n",
    ")\n",
    "tar_study = train_desc_raw.loc[CON, 'study_id'].unique()[0]\n",
    "tar_series = train_desc_raw.loc[CON, 'series_id'].unique()\n",
    "\n",
    "#(3)\n",
    "train_desc_raw.loc[CON, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf156f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CON = (\n",
    "    # (train_coord_raw.loc[:, 'study_id'] == tar_study) \n",
    "    (train_coord_raw.loc[:, 'series_id'].isin(values=tar_series))\n",
    ")\n",
    "train_coord_raw.loc[CON, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929d68ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(stop=len(tar_series)) : \n",
    "    check_img(dir_path=file_path, coord_df=train_coord_raw, desc_df=train_desc_raw, study_id=tar_study, series_id=tar_series[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818d73a9",
   "metadata": {},
   "source": [
    "#### 02.3. **`train_label_coordinates` 파악**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0e40da",
   "metadata": {},
   "source": [
    "- 일부 컬럼에서 결측값 파악 $ \\rightarrow{} $ **대부분** study_id 별 전체 이미지 파일(해당되는 모든 study_id)에서 디스크 위치가 파악이 안되서\n",
    "\n",
    "$ \\hspace{0.5cm} $ (파악되지 않는 부분은 추후 모델링하며 성능 개선이 필요하다고 판단되면 더 탐색)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05b465d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1)\n",
    "diagnose_df(df=train_label_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b69e43",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21960fd8",
   "metadata": {},
   "source": [
    "## 03. **PREPARE DATASETS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb22c91",
   "metadata": {},
   "source": [
    "##### 03.1. **WIDE FORM TO LONG FORM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e8798d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1)\n",
    "train_label_lf = pd.concat(\n",
    "    objs=[reshape_row(row) for _, row in train_label_raw.iterrows()], \n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "#(2)\n",
    "train_label_lf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0227ab81",
   "metadata": {},
   "source": [
    "#### 03.2. **MERGE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc75c54",
   "metadata": {},
   "source": [
    "$ \\hspace{0.5cm} $ ① `train_raw` (inner_join) `train_coord_raw` $ \\Rightarrow{} $ `train_raw`\n",
    "\n",
    "$ \\hspace{0.5cm} $ ② `train_raw` (inner_join) `train_desc` $ \\Rightarrow{} $ `train_raw`\n",
    "\n",
    "$ \\hspace{0.5cm} $ ③ `train_raw` (in) `train_image_study_ids`(*) $ \\Rightarrow{} $ `train_raw`\n",
    "\n",
    "$ \\hspace{0.5cm} $ ④ `train_raw` (in) `train_image_series_ids`(*) $ \\Rightarrow{} $ `train_raw`\n",
    "\n",
    "$ \\hspace{0.5cm} $ (*) : train_image 디렉토리에 존재하는 모든 study_id, series_id 리스트들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2fa946",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1)\n",
    "train_raw = pd.merge(\n",
    "    left=train_label_lf,\n",
    "    right=train_coord_raw,\n",
    "    on=['study_id', 'condition', 'level'],\n",
    "    how='inner' # left ?\n",
    ")\n",
    "\n",
    "#(2)\n",
    "train_raw = pd.merge(\n",
    "    left=train_raw,\n",
    "    right=train_desc_raw,\n",
    "    on=['study_id', 'series_id'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "#(3)\n",
    "# train_img_study_ids = np.array(object=os.listdir(path=f'{file_path}/train_images/'))\n",
    "# CON = train_raw.loc[:, 'study_id'].isin(values=train_img_study_ids)\n",
    "# train_raw = train_raw.loc[CON, :]\n",
    "\n",
    "#(4)\n",
    "train_raw.loc[:, 'row_id'] = (\n",
    "    train_raw['study_id'].astype(str) + '_' +\n",
    "    train_raw['condition'].str.lower().str.replace(' ', '_') + '_' +\n",
    "    train_raw['level'].str.lower().str.replace('/', '_')\n",
    ") \n",
    "\n",
    "#(5)\n",
    "train_raw = relocate_col(df=train_raw, tar_col='row_id', std_col='study_id', how='before')\n",
    "train_raw = relocate_col(df=train_raw, tar_col='series_id', std_col='study_id', how='after')\n",
    "train_raw = relocate_col(df=train_raw, tar_col='series_description', std_col='series_id', how='after')\n",
    "train_raw = relocate_col(df=train_raw, tar_col='instance_number', std_col='series_description', how='after')\n",
    "train_raw = relocate_col(df=train_raw, tar_col='condition', std_col='y', how='after')\n",
    "train_raw = relocate_col(df=train_raw, tar_col='severity', std_col='y', how='after')\n",
    "\n",
    "#(6)\n",
    "train_raw.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df59ef80",
   "metadata": {},
   "source": [
    "#### 03.3. **CHECK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8191988c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1)\n",
    "diagnose_df(df=train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8db6273",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(2)\n",
    "CON = (train_raw.loc[:, 'severity'].isna())\n",
    "temp_01 = train_raw.loc[CON, 'study_id'].unique()\n",
    "temp_02 = train_raw.loc[CON, 'series_id'].unique()\n",
    "print(f'>> study id that has NA severitiy : {len(temp_01)}, series_id : {len(temp_02)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b9c1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw.loc[CON, :].head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddd7c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CON = (train_raw.loc[:, 'study_id'].isin(values=study_id_nt5_level))\n",
    "diagnose_df(df=train_raw.loc[CON, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46d949e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CON = (train_coord_raw.loc[:, 'study_id'].isin(values=temp))\n",
    "train_coord_raw.loc[CON, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e33cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CON = (train_label_lf.loc[:, 'study_id'].isin(values=study_id_nt5_level))\n",
    "diagnose_df(df=train_label_lf.loc[CON, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4857111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(3)\n",
    "train_raw.loc[:, ['study_id', 'series_description', 'condition']].drop_duplicates().groupby(by=['series_description', 'condition']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f996fd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(3-PLUS)\n",
    "CON = (\n",
    "    (train_raw.loc[:, 'series_description'] == 'Sagittal T1') &\n",
    "    (train_raw.loc[:, 'condition'] == 'Spinal Canal Stenosis')\n",
    ")   \n",
    "train_raw.loc[CON, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b824614e",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_vid(dir_path=file_path, coord_df=train_coord_raw, desc_df=train_desc_raw, study_id=3637444890, series_id=3951475160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e32c87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CON = (train_raw.loc[:, 'condition'] == 'Spinal Canal Stenosis')\n",
    "train_raw.loc[CON, ['study_id', 'series_id', 'condition']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48896f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_vid(dir_path=file_path, coord_df=train_coord_raw, desc_df=train_desc_raw, study_id=4282019580, series_id=1547999333)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4347a6d1",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81515807",
   "metadata": {},
   "source": [
    "## 04. **EDA 결론 및 추후 모델링 고려사항**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbac4fb",
   "metadata": {},
   "source": [
    "##### 04.1. **EDA 결론**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c548714e",
   "metadata": {},
   "source": [
    "- 총 $ \\, 1975 $ 개의 study_id 중 $ \\, 3 $ 개의 유일한 촬영기법(description)을 갖지 않는 study_id 파악 : $ 343 $ 개\n",
    "\n",
    "$ \\hspace{0.5cm} $ ($ 340 $ 개의 study_id는 $ \\, 3 $ 개 이상의 중복된 촬영기법, $ \\, 3 $ 개의 study_id는 $ \\, 2 $ 개 이하의 촬영기법)\n",
    "\n",
    "- 총 $ \\, 6294 $ 개의 study_id 중 중복된 촬영 기법을 갖는 series_id 파악 : $ \\, 714 $ 개\n",
    "\n",
    "$ \\hspace{0.5cm} $ ($ 700 $ 개의 study_id는 axial T2 촬영기법, $ \\, 14 $ 개의 study_id는 Sagittal T1 촬영기법)\n",
    "\n",
    "$ \\hspace{0.5cm} \\Rightarrow{} $ 02.2.axial T2는 L(좌)SS, R(우)SS 구분을 위해 중복 생성됨, **단  sagittal T1은 좀 더 봐야할 듯(추후 확인 필요)**\n",
    "\n",
    "- 총 $ \\, 1974 $ 개의 study_id 중 $ \\, 5 $ 개의 디스크 위치를 갖지 않는 study_id 파악 : $ \\, 183 $ 개\n",
    "\n",
    "$ \\hspace{0.5cm} \\Rightarrow{} $ **inner join 과정에서 삭제됨(추후 확인 필요)**\n",
    "\n",
    "- 여러 이미지(instance) 중 일부만 `train_series_description` 데이터셋의 좌표가 찍혀있는 이유 $ \\rightarrow{} $ 디스크 위치의 정확한 식별이 안되기 때문\n",
    "\n",
    "- 촬영 기법(description) 별로 증상(condition)이 그룹화됨\n",
    "\n",
    "- description = \"Sagittal T1\" & condition=\"Spinal Canal Stenosis\" 인 건 확인 $ \\rightarrow{} $ 추후 확인 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2330a4d3",
   "metadata": {},
   "source": [
    "##### 04.2. **모델링 고려 사항**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b475dce7",
   "metadata": {},
   "source": [
    "(1) 확인된 목표 \n",
    "\n",
    "- 여러 이미지 중 유의미한 (좌표가 찍힌?, 증상을 알 수 있는?) 이미지 구분\n",
    "\n",
    "- 유의미한 이미지 중 심각도(severity) 를 $ \\, 3 $ 단계의 확률(소프트맥스) 파악 \n",
    "\n",
    "(2) 방안\n",
    "\n",
    "- 1 모델 처리? : 무의미한 이미지(좌표가 없는 이미지)에 대하여 좌표를 (0, 0), 증상을 `unknown` 처리 \n",
    "\n",
    "- 2 모델 처리? : 무의미한 이미지와 유의미한 이지를 객체 탐식을 통해 식별 ? "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9045607,
     "sourceId": 76727,
     "sourceType": "competition"
    },
    {
     "datasetId": 478,
     "sourceId": 974,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 159.349778,
   "end_time": "2024-08-04T03:40:44.363345",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-04T03:38:05.013567",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
